{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lexiconium/textual-inversion/blob/main/conceptualizer.ipynb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "T_caT1KVpSTg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title ## Install Dependencies\n",
    "\n",
    "!pip install git+https://github.com/lexiconium/textual-inversion > /dev/null 2>&1"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "cellView": "form",
    "id": "s9U3Ln-ypSTk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "#@title ## Import Dependencies\n",
    "\n",
    "import os\n",
    "import secrets\n",
    "import shutil\n",
    "\n",
    "import gradio as gr\n",
    "import torch\n",
    "import torchvision\n",
    "from diffusers import AutoencoderKL, PNDMScheduler, UNet2DConditionModel\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "\n",
    "from textual_inversion.dataset import TextualInversionDataset\n",
    "from textual_inversion.pipeline import TextualInversionDiffusionPipeline, TextualInversionDiffusionTrainingConfig"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "cellView": "form",
    "id": "mXKZaCBbpSTl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title ## Configuration\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown #### 1. Model and training configs\n",
    "\n",
    "pretrained_model_name_or_path = \"CompVis/stable-diffusion-v1-4\"  #@param {type:\"string\"}\n",
    "size = 512  #@param {type:\"integer\"}\n",
    "num_training_epochs = 1000  #@param {type:\"integer\"}\n",
    "training_batch_size = 1  #@param {type:\"integer\"}\n",
    "gradient_accumulation_steps = 4  #@param {type:\"integer\"}\n",
    "learning_rate = 1e-4  #@param {type:\"number\"}\n",
    "adam_beta1 = 0.9  #@param {type:\"number\"}\n",
    "adam_beta2 = 0.999  #@param {type:\"number\"}\n",
    "adam_weight_decay = 1e-2  #@param {type:\"number\"}\n",
    "adam_epsilon = 1e-8  #@param {type:\"number\"}\n",
    "lr_scheduler = \"constant\"  #@param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]\n",
    "warmup_ratio = 0.2  #@param {type:\"number\"}\n",
    "num_warmup_steps = 0  #@param {type:\"integer\"}\n",
    "mixed_precision = \"fp16\"  #@param [\"no\", \"fp16\", \"bf16\"]\n",
    "seed = 42  #@param {type:\"integer\"}\n",
    "use_auth_token = True  #@param {type:\"boolean\"}\n",
    "output_dir = \"outputs\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown #### 2. Conceptualization config\n",
    "#@markdown One must write in `placeholder_token` and `initializer_token`. \\\\\n",
    "#@markdown When one wants to train an exotic cat picture, for instance, `placeholder_token`\n",
    "#@markdown and `initializer_token` could be \"\\<exotic-cat\\>\", \"cat\" respectively.\n",
    "\n",
    "learnable_property = \"object\"  #@param [\"object\", \"style\"]\n",
    "placeholder_token = \"<exotic-cat>\"  #@param {type:\"string\"}\n",
    "initializer_token = \"cat\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ---"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "cellView": "form",
    "id": "0sMDAJwSpSTm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title ## Upload Data\n",
    "\n",
    "g_save_dir = \"\"\n",
    "\n",
    "with gr.Blocks() as uploader:\n",
    "    with gr.Row().style(equal_height=True):\n",
    "        uploaded_files = gr.File(\n",
    "            file_count=\"multiple\",\n",
    "            label=\"Upload images\",\n",
    "            interactive=True\n",
    "        )\n",
    "\n",
    "        with gr.Column():\n",
    "            status_msg = gr.Textbox(\n",
    "                value=\"If uploaded, click Save.\",\n",
    "                lines=10,\n",
    "                label=\"Status\",\n",
    "                show_label=False,\n",
    "                interactive=False\n",
    "            )\n",
    "            save_button = gr.Button(\"Save\", variant=\"primary\")\n",
    "\n",
    "\n",
    "    def save_fn(tmpfiles):\n",
    "        global g_save_dir\n",
    "\n",
    "        save_dir = os.path.join(os.getcwd(), secrets.token_hex(nbytes=16))\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        for tmpfile in tmpfiles:\n",
    "            shutil.copy(tmpfile.name, save_dir)\n",
    "\n",
    "        g_save_dir = save_dir\n",
    "\n",
    "        return \"Done.\"\n",
    "\n",
    "\n",
    "    save_button.click(\n",
    "        save_fn,\n",
    "        inputs=[uploaded_files],\n",
    "        outputs=[status_msg]\n",
    "    )\n",
    "\n",
    "uploader.launch()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "cellView": "form",
    "id": "2ovAPoHzpSTo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title ## Login to Hugging Face Hub\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title ## Setup\n",
    "\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"tokenizer\",\n",
    "    use_auth_token=use_auth_token\n",
    ")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"text_encoder\",\n",
    "    use_auth_token=use_auth_token\n",
    ")\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"unet\",\n",
    "    use_auth_token=use_auth_token\n",
    ")\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"vae\",\n",
    "    use_auth_token=use_auth_token\n",
    ")\n",
    "scheduler = PNDMScheduler(\n",
    "    beta_start=0.00085,\n",
    "    beta_end=0.012,\n",
    "    beta_schedule=\"scaled_linear\",\n",
    "    num_train_timesteps=1000,\n",
    "    tensor_format=\"pt\"\n",
    ")\n",
    "\n",
    "pipeline = TextualInversionDiffusionPipeline(\n",
    "    tokenizer=tokenizer,\n",
    "    text_encoder=text_encoder,\n",
    "    unet=unet,\n",
    "    vae=vae,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "training_config = TextualInversionDiffusionTrainingConfig(\n",
    "    placeholder_token=placeholder_token,\n",
    "    initializer_token=initializer_token,\n",
    "    num_training_epochs=num_training_epochs,\n",
    "    training_batch_size=training_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    adam_beta1=adam_beta1,\n",
    "    adam_beta2=adam_beta2,\n",
    "    adam_weight_decay=adam_weight_decay,\n",
    "    adam_epsilon=adam_epsilon,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    mixed_precision=mixed_precision,\n",
    "    seed=seed,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(\n",
    "        (size, size),\n",
    "        torchvision.transforms.InterpolationMode.BICUBIC\n",
    "    ),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "        std=[0.26862954, 0.26130258, 0.27577711]\n",
    "    )\n",
    "])\n",
    "dataset = TextualInversionDataset(\n",
    "    data_dir=g_save_dir,\n",
    "    transforms=transforms,\n",
    "    tokenizer=tokenizer,\n",
    "    placeholder_token=placeholder_token,\n",
    "    learnable_property=learnable_property\n",
    ")\n",
    "\n",
    "pipeline = pipeline.train(training_config=training_config, dataset=dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title ## Generate\n",
    "\n",
    "def text_to_image(\n",
    "    prompt,\n",
    "    num_samples,\n",
    "    height,\n",
    "    width,\n",
    "    num_inference_steps,\n",
    "    guidance_scale\n",
    "):\n",
    "    with torch.autocast(\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        images = pipeline(\n",
    "            [prompt] * num_samples,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale\n",
    "        ).images\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "interface_inputs = [\n",
    "    gr.Textbox(placeholder=\"Write a prompt you want to generate in image.\", label=\"Prompt\"),\n",
    "    gr.Number(value=2, label=\"Number of samples\", precision=0),\n",
    "    gr.Number(value=512, label=\"Height\", precision=0),\n",
    "    gr.Number(value=512, label=\"Width\", precision=0),\n",
    "    gr.Slider(minimum=10, maximum=100, value=50, step=1, label=\"Number of inference steps\"),\n",
    "    gr.Slider(minimum=1, maximum=10, value=7.5, step=0.1, label=\"guidance_scale\")\n",
    "]\n",
    "interface_output = [gr.Gallery(label=\"Images from prompt\", interactive=False)]\n",
    "\n",
    "gr.Interface(\n",
    "    fn=text_to_image,\n",
    "    inputs=interface_inputs,\n",
    "    outputs=interface_output\n",
    ").launch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/lexiconium/textual-inversion/blob/main/conceptualizer.ipynb",
     "timestamp": 1662750478862
    }
   ],
   "toc_visible": true
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}